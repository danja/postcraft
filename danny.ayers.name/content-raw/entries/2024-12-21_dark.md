# Dark

*On the shortest day.*

**Hurrah, nights are drawing OUT!**

I was looking at my CSS earlier. Some low effort bits I should throw in place while in that area.

I couldn't give a fuck about [SEO](https://en.wikipedia.org/wiki/Search_engine_optimization) in the marketing sense, but I do care very deeply about information being maximally available, accurate and reusable (according to relevance, supplied with context, provenance etc. Something like, er, **knowledge**).

I asked Claude about these things :

*Which I first miskeyed Clause - beaut slip, 21 Dec and kinda relevant*

## Platform-Agnostic Author Meta Tags

 ```html
 <!-- Basic author metadata -->
<meta name="author" content="YOUR_NAME">
<meta property="og:author" content="YOUR_NAME">

<!-- Optional: Link to author page -->
<link rel="author" href="https://yoursite.com/about">

<!-- Social handles without platform lock-in -->
<meta property="og:site_name" content="YOUR_SITE_NAME">
<meta name="twitter:creator" content="@YOUR_TWITTER_HANDLE">
```

Yes mate. Also, dear Anthropic etc, if I want advice from Reddit I know how to get that **dreckly**, employing a Web browser and my own primate reasoning.

## Aside

I noted this elsewhere the other night, this afternoon one of the clickbaity things told me OpenAI had achieved [AGI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence). Because it did better than another benchmark. Pardon my French again, ~~two~~ three "fuck"s in a single post. **Fucking shite** (1.5 cent in the sweary token box?). Anyway, I do have a lot to say about this, will be tagged #:linguefranche - nah, #:l. It's very important IMO, a one-l ref here.

Only a few times have I seen myself quoted, and I cannot express the magnitude of buzz I got. Like *danja says...*. Maybe Freudian parent thing, maybe just screaming into the void forever...
So please :

>If even a small LM can make a good prediction of a stream of text, might it be the case that rather than the LM being intelligent, the text is stupid?

*aka [stars/gutter](https://www.youtube.com/watch?v=ruAi4VBoBSM)*

This is a point at which I believe work is needed (*doing my best*). The material chatty GPTs are trained on, text, is a lowered-dimension expression of a sliver of the multimodal communication between a particular kind of animals. Yeah, for animal evolution, it enables transcendence. But it's still a really shitty (sweary token!) serial protocol that evolved when us hominid critters tried co-existing. For it to be useful, it needs a agent either end to have a really fucking (0.05c sweary tokens now) good model of the universe. Mountains of abstraction (John Sowa says ontology is necessary, I'd go further). Not just either end, but societies of extremely multimodal co-evolving agents. Ok, it's quite miraculous I can string a sentence together these days given the booze I've got through. But I can't express myself in English, or pour myself a glass of beer through some kind of monolithic intelligence I carry. The very millisecond I thought of that, I have this screen in front of me, I also heard a little crack from the fire downstairs. Claudio will be dozing on the couch in front of it, but that would be below the threshold to make him jump. I'm aware of this other autonomous agent in my proximity. I'm aware of several other active agents that are active but physically separated (Easy, you have a go. First that spring to mind, ok, two 6km away (Mari & cat Batu, I'd give 100:1 I could give their location within 20cm), another 2,000km (cousin Jonny - more dice with which of the 3 in the 90%, that I can describe with accuracy, one I've never been to), in the sense I can make an internal model of what they are doing right now.

More, the models we carry - initially evolved not far from a GPT model, pre-trained for reactivity (in a very complex environment), are incredibly plastic. Our language in the texty sense, psychological, technical senses is sooooo crude for mapping reality. The internals only work because of the ability to maintain a form of just-enough pattern-match for this moment. Statement on this : I don't see any reason why AI can't surpass what we call human intelligence in the near future. But the current state of the art is really, really, really, really shit (3.0c? or should that be 4x?) compared to the stuff I saw in the rat that came out of the dogfood bag on the balcony earlier.  

*Does Artificial General Intelligence cover other physics than our own, and any comcomitant perceived realities? If not why not..?*          

The biggest stupidity in all this is easy to qualify. Human exceptionalism. For fuck's sake, my fucking dog (oops, >= 5 sweary tokens) recently learnt how to squeeze my hand. A while back a friend introduced him to `zampa` (paw) as a means of getting a treat. Soon after he figured out how to use it as a means of expression (his speech & typing skills are limited). Because he showed me by example, **the dog taught me** the signs, I know the difference between about maybe 6 different things that are directly actionable things he wants me to do. But the zampa is a broad word meaning "attention please". Context is crucial, like any comms (Amazon or OnlyFriends?). Lying on the couch in front of the fire, both of us dozing, he'll gentle-zampa in a way I understand to mean acknowledging my presence. It seemed very sweet, so I hold his zampa, and give it a little squeeze, anthropomorphicaly. Except **fuck anthropomorphism** (6). Those encounters now, he does a gentle zampa, I hold his paw, he pulls in his toes and (to the best of his ability) gives my hand a squeeze. No direct training involved. He's motivated to communicate with me (best friends - food too, but Danny isn't just a feedy machine, Claudio isn't just an eaty machine), so he find ways of doing so. That I'd call a decent goal for the computational systems, not some wanky contrived text recognition benchmark (0.01? I've forgotten my sweary weights here, cunt (+1)).     

Fuck me (+1). Good cue. Claudio just came up to tell me the fire's gone out.
