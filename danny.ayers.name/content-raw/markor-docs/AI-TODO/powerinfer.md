Big boost for local models. Paper link doesn't work on my phone, will try again when I make it to desk from bed :)

A spurious idea before I forget: might there be a way to use a similar approach with quantization? 
->

@TheBlokeAI @ggerganov
https://github.com/SJTU-IPADS/PowerInfer

@kidehen @emeka @Scobleizer @IntuitMachine @vincecate

Train high precision, identify hot/cold nodes however PowerInfer does it, quantize correspondingly? First guess at how to do the sums at runtime - 3 virtual calculation engines: precise; mixed; low bit. Pipe accordingly (however PowerInfer does it).

@TheBlokeAI 
@ggerganov @danbri 
