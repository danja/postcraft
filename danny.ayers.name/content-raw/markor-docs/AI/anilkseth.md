@anilkseth, re. what you said on R4, crudely paraphrased, "AI can't be conscious". I will read your material, but I can't leave this unchallenged.
Ok, our consciousness is tied to our nature, notably we are embodied as living beings in an environment. Lots of physical & social evolution has made us very special. But we can make sensors & actuators, compute analogs of animal intelligence. We can simulate physical systems.

Ok, I think it's clear we are only at baby steps in all this. But there's nothing to suggest that living consciousness falls outside a materialistic matrix. If we can emulate such systems, then surely this too is in scope?

My own best guess is that consciousness is simply an emergent property of social agents. In a sense it's nothing special, we exaggerate its significance out of intellectual exceptionalism. It's the modern 'soul'. 

The preconditions are: autonomy & actuaction within a shared environment; perception; a level of computation that facilitates prediction; means of communication. There are many phase changes going from a mere entity to a conscious being. Within animals' models of their environment, cognition goes beyond recognizing food/danger to identifying other organisms, at least as predator/prey. Within a species, cooperative activity is usually evolutionarily beneficial, which makes any communication useful. 

In parallel, the more complex living creatures have interoception, a sense of self on a mechanical level. Taking these together, it isn't a massive step in sophistication to develop both a more abstract sense of others, but also one of self. Communication is much more efficient when there's a shared model of the universe (you only have to exchange diffs). I don't think language is necessary for consciousness per se, but the same evolutionary trends lead to both.

Back to the original point, while the evolution of life led to our consciousness, there's no reason we can't take shortcuts to get AI consciousness. 
Large *language* models capture a representation we pass between each other, only a subset of the system as a whole. Other views, like those embodiment offers, are needed to get closer to what is going on in our heads. From current AI, to promote consciousness, the LLM view probably needs projecting back, like shining a laser back at the shadows in Plato's cave to examine what is in the outside world and/or inside our heads.