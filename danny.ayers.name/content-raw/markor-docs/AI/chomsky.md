I have massive respect for the work Chomsky has done over the years. Sometimes IMHO (and that of scientific consensus) he's been wide of the mark.
I believe this to be another such case.
The underlying flaw is that of human exceptionalism. 
I completely agree that the current generation of AI is an outrageous number of degrees of magnitude more stupid than any human (or for that matter, any stick insect). 
But that says nothing about the potential capabilities of such systems.

It's like the brilliant Robert Penrose's notion that consciousness must involve Quantum. On one level, it's trivially true. I believe research has shown that there's a quantum physics component in plant photosynthesis. Life in this physical universe has evolved taking advantage of every phenomenon that might help it continue.
On another level, it's saying "we can't cover A with current theories, so the other unknown B must be responsible". 

Similarly, Chomsky is saying that because the weirdo bunch of linear algebra in current Deep Learning doesn't currently cover human intelligence, it has to be fundamentally lacking somewhere. On what basis? And where?

Both hark back to the old question of locating the soul. It's clearly a property of humans, following our understanding of biology and logic, properties of humans must be located somewhere, but is it liver, heart or brain?

Same applies in theory of mind, which Pierce pushed forward greatly a couple of centuries ago with the notion of 'qualia'. 
But there's still this kind of assumption: there exists this thing we haven't yet pinned down, so it must be down to some f'ing ineffable essence, which only humans possess. What nonsense.

There isn't a definitive finite definition of what intelligence actually is, but we do have some hand-wavy understanding. It's a characteristic that helps organisms survive and procreate by giving them the ability to make predictions. On a timeline, given this situation, what is likely to happen next. Hand-wavy again : to do this, a model of reality is created, and like an automata let run to the next step. A key part of model creation is copying previously experienced patterns - exactly the plaguarism Chomsky sees as a fault in current AI.

I personally believe the current talk around AGI is seriously misguided, not least by companies wishing to sell product.
But I'm sure human-level intelligence is possible in silico. Intelligence in our sense has been done at least once within this universe, built on lots of little interconnected components. While we are still only taking baby steps in analysing how this works in humans (brain, biome, endocrine system...society), there's no magic needed. 
AGI is a distraction, as it is currently framed - in comparison to human intelligence. It is bound to fall short, I would guess for at least another century on the currently trajectory. We don't even have *general* intelligence ourselves, we have an intelligence absolutely tied to the environment in which we developed as a breedable organism. 

But right now we are the Deus ex Machina - we can get computers to create models that aren't bound like us. The quest for human-like intelligence is fair enough, we don't know any better. But it seems highly improbable that there aren't other forms of intelligence possible that behave completely differently that can be built in our universe. That's what computers are for. 


