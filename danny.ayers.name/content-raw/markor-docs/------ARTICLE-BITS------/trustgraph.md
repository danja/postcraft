Heads-up folks : check TrustGraph AI engine. 
For my own work I've identified what I believe to be the fastest track forward in this domain. The specifics remain to be seen, but the prerequisites can be itemised. I only just heard of @trustgraphAI (hat tip @TrustSpooky), skimmed docs, 

but I reckon it ticks all the boxes.

I've got proper write-ups on all this in progress, but stand-out essentials that aren't already in everyone's toolbag:
1. Web compatibility at a fundamental level (Linked Data)
2. Infrastructure for agent-agent communication

For 1. I'm talking about the Web in the sense of the Giant Global Graph (one of timbl's past rebranding phrases). The WWW is already a massive knowledgebase. But the predominant facade we see is a big read-only document database/viewer. Deeper interactivity is mostly confined to domain-local proprietary apps like search engines and the popular social media platforms. These operate as fenced-off islands, largely isolated from the rest of the world. But it only takes a small shift in perspective to exploit the Web to its full potential. We have the technology! Linked Data encompasses 

---

Heads-up folks  : TrustGraph AI engine. 
For my own work I've identified what I believe to be the fastest track forward in this domain. The specifics remain to be seen, but the prerequisites can be itemised. I only just heard of TrustGraph (hat tip @TrustSpooky), 
->

but I reckon it ticks all the boxes.
https://trustgraph.ai/
I've got proper write-ups in progress, but stand-out essentials that aren't already in everyone's toolbag:
1. Web compatibility at a fundamental level (Linked Data)
2. Infrastructure for agent-agent communication
TG covers 1. by using RDF for knowledge graphs; 2. they use Apache Pulsar, pub/sub connectivity.



All elective devs know the mixed emotions on encountering a project similar to your own Big New Idea. On the one hand, it's validation, you probably are onto something. On the other - they got there first! 
. But there isn't any 'breakthrough' within either, all the components are already out there. The nearest to innovation is seeing some potential in gluing them together (which seems a no-brainer).

I find the overlap between what I've been working on and TG very pleasing. Although our application target areas, implementation nuts & bolts etc are very different, at a conceptual level they are essentially the same system. Which we arrived at independently.

Heads-up folks  : TrustGraph AI engine. 
For my own work I've identified what I believe to be the fastest track forward in this domain. The specifics remain to be seen, but the prerequisites can be itemised. I only just heard of TrustGraph (hat tip @TrustSpooky), 
but I reckon it ticks all the boxes.

I've got proper write-ups in progress, but stand-out essentials that aren't already in everyone's toolbag:

1. Web compatibility at a fundamental level (Linked Data)
2. Infrastructure for agent-agent communication
TG covers 1. by using RDF for knowledge graphs; 2. they use Apache Pulsar, pub/sub connectivity.

https://trustgraph.ai/

 -
