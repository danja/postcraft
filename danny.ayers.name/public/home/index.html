<!DOCTYPE html>
<html lang="en">

<head>
    <title>Rawer</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <!-- TODO make like this, place from manifest
    <link rel="stylesheet" href="css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="css/grid-columns.css" type="text/css" />
    <link rel="stylesheet" href="css/style.css" type="text/css" />
    -->
    <link rel="stylesheet" href="css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="css/grid-columns.css" type="text/css" />
    <link rel="stylesheet" href="css/style.css" type="text/css" />

</head>

<body>
    <header id="main-header">
        <h1>
           Rawer
        </h1>
    </header>
    <div class="grid-container">
        <div class="main-grid-item directory">
            <p><strong>Under Construction</strong></p>
            <p><em>there are many to-dos</em></p>
            <!--
            <h2>directory</h2>
            <p>i cinque secoli, ma anche al passaggio alla videoimp</p>
            -->
        </div>
        <div class="main-grid-item articles">
            <!-- h2>articles</h2 -->
            <article>
                <!-- POST CONTENT TEMPLATE -->

<article class="post-content">
        <a href="entries/2024-08-25_blog-improving.html">#</a>
    <h1>Improving this Blog</h1>
<p>I&#39;ve been away for a week, just long enough to forget where I was up to.</p>
<pre><code>cd ~/github-danny/transmissions
./run postcraft /home/danny/github-danny/postcraft/danny.ayers.name
</code></pre>
<p>That&#39;s giving me the journal. I want entries.
That&#39;s in :</p>
<pre><code>/home/danny/github-danny/postcraft/danny.ayers.name/manifest.ttl
</code></pre>
<p>Grrr. It&#39;s in chrono order.
OK, tweaked :</p>
<pre><code>src/services/postcraft/FrontPagePrep.js
</code></pre>
<p>There are some little todos need doing around there, but it&#39;s good enough for now.</p>
<p>Permalinks next.</p>
<pre><code>https://danny.ayers.name/home/2024-08-25_blog-improving.html
</code></pre>
<p>needs to be relative.</p>
<p>files are under</p>
<pre><code>http://localhost/DANNY.AYERS.NAME/entries/
</code></pre>
<p>Sheesh, this thing needs so much refactoring!!</p>
<p>Found it :</p>
<pre><code>/home/danny/github-danny/transmissions/src/services/postcraft/PostcraftPrep.js

was
message.contentBlocks.link = message.siteURL + &#39;/&#39; + message.contentBlocks.relURL
</code></pre>
<ul>
<li>images</li>
<li>Atom feed</li>
<li>add articles, journal entries etc</li>
</ul>

</article>
<p class="post-title">
    <a href="entries/2024-08-25_blog-improving.html">
        Improving this Blog
    </a>
</p> <em>2024-08-25</em><!-- POST CONTENT TEMPLATE -->

<article class="post-content">
        <a href="entries/2024-08-15_linux-speedup.html">#</a>
    <h1>Linux Performance Tips</h1>
<p>I think most of these will work in most distros, but I&#39;ve only tried on Ubuntu, ymmv.</p>
<p><a href="https://www.zabbix.com/">https://www.zabbix.com/</a> - big monitoring app</p>
<p><a href="https://nicolargo.github.io/glances/">https://nicolargo.github.io/glances/</a> - looks like htop with more features</p>
<h1>Linux Commands to Optimize Application Performance</h1>
<h2>Process Priority</h2>
<ul>
<li><code>nice</code>: Set the priority of a new process</li>
<li><code>renice</code>: Alter the priority of an existing process</li>
</ul>
<h2>CPU Core Usage</h2>
<ul>
<li><code>taskset</code>: Set or retrieve a process&#39;s CPU affinity</li>
<li><code>cgroups</code>: Control groups for resource allocation</li>
</ul>
<h2>I/O Throughput</h2>
<ul>
<li><code>ionice</code>: Set or change the I/O scheduling class and priority</li>
<li><code>iotop</code>: Monitor I/O usage by processes</li>
</ul>
<h2>Memory Management</h2>
<ul>
<li><code>ulimit</code>: Set or get user limits for system resources</li>
<li><code>vmstat</code>: Report virtual memory statistics</li>
<li><code>free</code>: Display amount of free and used memory in the system</li>
</ul>
<h2>Additional Tools</h2>
<ul>
<li><code>top</code> / <code>htop</code>: Monitor system processes and resource usage</li>
<li><code>perf</code>: Linux profiling tool for performance analysis</li>
</ul>
<hr>
<h1>Detailed Linux Commands for Performance Optimization</h1>
<h2>Process Priority</h2>
<h3>nice</h3>
<p>Description: Starts a process with a modified scheduling priority.
Example:
<code>nice -n 10 ./my_script.sh</code>
This runs <code>my_script.sh</code> with a lower priority (nice value of 10).</p>
<h3>renice</h3>
<p>Description: Alters the scheduling priority of a running process.
Example:
<code>renice -n -5 -p 1234</code>
This increases the priority of process with PID 1234 (nice value of -5).</p>
<h2>CPU Core Usage</h2>
<h3>taskset</h3>
<p>Description: Sets or retrieves a process&#39;s CPU affinity.
Example:
<code>taskset -c 0,1 ./my_app</code>
This runs <code>my_app</code> on CPU cores 0 and 1 only.</p>
<h3>cgroups</h3>
<p>Description: Control groups for resource allocation (more complex, typically configured via system files).
Example:
<code>echo 950000 &gt; /sys/fs/cgroup/cpu/my_group/cpu.cfs_quota_us</code>
This limits processes in <code>my_group</code> to 95% of one CPU core.</p>
<h2>I/O Throughput</h2>
<h3>ionice</h3>
<p>Description: Sets or changes the I/O scheduling class and priority of a process.
Example:
<code>ionice -c 2 -n 0 -p 1234</code>
This sets process 1234 to use the best-effort I/O scheduling class with highest priority.</p>
<h3>iotop</h3>
<p>Description: Monitors I/O usage by processes.
Example:
<code>iotop -o</code>
This shows only processes or threads actually doing I/O.</p>
<h2>Memory Management</h2>
<h3>ulimit</h3>
<p>Description: Sets or gets user limits for system resources.
Example:
<code>ulimit -v 1000000</code>
This limits the virtual memory available to the shell and its child processes to 1GB.</p>
<h3>vmstat</h3>
<p>Description: Reports virtual memory statistics.
Example:
<code>vmstat 5 3</code>
This displays memory statistics every 5 seconds, 3 times.</p>
<h3>free</h3>
<p>Description: Displays the amount of free and used memory in the system.
Example:
<code>free -h</code>
This shows memory usage in human-readable format.</p>
<h2>Additional Tools</h2>
<h3>top / htop</h3>
<p>Description: Monitors system processes and resource usage in real-time.
Example:
<code>top</code>
or for htop:
<code>htop</code>
Both provide an interactive process viewer.</p>
<h3>perf</h3>
<p>Description: Linux profiling tool for performance analysis.
Example:
<code>perf stat ./my_app</code>
This provides basic performance statistics for <code>my_app</code>.</p>
<h3>parallel</h3>
<p>Description: Executes jobs in parallel using multiple CPU cores.
Example:
<code>parallel -j 8 my_script.sh ::: input1 input2 input3 input4</code>
This runs <code>my_script.sh</code> on 8 CPU cores simultaneously, processing different inputs.</p>
<h3>nproc</h3>
<p>Description: Print the number of processing units available.
Example:
<code>nproc</code>
This prints the number of available cores, which can be used in scripts to dynamically allocate tasks.</p>
<hr>
<h1>Explanation of <code>ps -o pid,pri,ni,cmd -p 177213</code></h1>
<p>This command uses the <code>ps</code> (process status) utility to display information about a specific process:</p>
<ul>
<li><code>ps</code>: The base command to report process status</li>
<li><code>-o pid,pri,ni,cmd</code>: Specifies the output format<ul>
<li><code>pid</code>: Process ID</li>
<li><code>pri</code>: Priority of the process</li>
<li><code>ni</code>: Nice value of the process</li>
<li><code>cmd</code>: The command with all its arguments</li>
</ul>
</li>
<li><code>-p 177213</code>: Selects the process with PID 177213</li>
</ul>
<p>This command will output a table with four columns:</p>
<ol>
<li>PID (Process ID): The unique identifier for the process</li>
<li>PRI (Priority): The current priority of the process</li>
<li>NI (Nice Value): The nice value, which affects process scheduling priority</li>
<li>CMD (Command): The command that started the process, including its arguments</li>
</ol>
<p>This is useful for checking the priority and nice value of a specific process, which can be helpful when optimizing system performance or troubleshooting issues related to process scheduling.</p>
<hr>
<h1>Explanation of <code>top -p 177213</code></h1>
<p>This command uses the <code>top</code> utility to monitor a specific process:</p>
<ul>
<li><code>top</code>: The base command that provides a dynamic real-time view of a running system</li>
<li><code>-p 177213</code>: Specifies the Process ID (PID) to monitor</li>
</ul>
<p>When executed, this command will:</p>
<ol>
<li>Launch the <code>top</code> program in your terminal</li>
<li>Display real-time information about only the process with PID 177213</li>
<li>Continuously update this information (typically every 3 seconds by default)</li>
</ol>
<p>The output will include:</p>
<ul>
<li>PID: Process ID (177213 in this case)</li>
<li>USER: User who owns the process</li>
<li>PR: Priority of the process</li>
<li>NI: Nice value of the process</li>
<li>VIRT: Virtual memory used</li>
<li>RES: Resident memory used</li>
<li>SHR: Shared memory used</li>
<li>S: Process status (e.g., R for running, S for sleeping)</li>
<li>%CPU: Percentage of CPU used by this process</li>
<li>%MEM: Percentage of memory used by this process</li>
<li>TIME+: Total CPU time used by the process</li>
<li>COMMAND: Command used to start the process</li>
</ul>
<p>This command is useful for monitoring the resource usage of a specific process in real-time, which can be helpful for performance tuning and troubleshooting.</p>
<p>Note: You can exit the <code>top</code> display by pressing &#39;q&#39;.</p>
<hr>
<h1>Explanation of taskset commands</h1>
<h2>Command 1: <code>taskset -cp 177213</code></h2>
<p>This command displays the current CPU affinity of a specific process:</p>
<ul>
<li><code>taskset</code>: The command to set or retrieve the CPU affinity of a process</li>
<li><code>-c</code>: Interprets mask as a list of CPUs instead of a bitmask</li>
<li><code>-p</code>: Operates on an existing PID (Process ID)</li>
<li><code>177213</code>: The PID of the process being queried</li>
</ul>
<p>This command will show which CPU cores the process with PID 177213 is currently allowed to run on.</p>
<h2>Command 2: <code>sudo taskset -cp 0-$(nproc --all) 177213</code></h2>
<p>This command sets the CPU affinity for a specific process to use all available CPU cores:</p>
<ul>
<li><code>sudo</code>: Runs the command with root privileges</li>
<li><code>taskset</code>: The command to set or retrieve the CPU affinity of a process</li>
<li><code>-c</code>: Interprets mask as a list of CPUs instead of a bitmask</li>
<li><code>-p</code>: Operates on an existing PID (Process ID)</li>
<li><code>0-$(nproc --all)</code>: Specifies the range of CPU cores to use<ul>
<li><code>0-</code>: Starts the range from CPU core 0</li>
<li><code>$(nproc --all)</code>: A command substitution that returns the number of available processing units</li>
</ul>
</li>
<li><code>177213</code>: The PID of the process whose CPU affinity is being set</li>
</ul>
<p>This command allows the process with PID 177213 to run on all available CPU cores, potentially improving its performance if it can utilize multiple cores effectively.</p>
<p>Note: Using <code>sudo</code> may be necessary to change the CPU affinity of processes you don&#39;t own.</p>

</article>
<p class="post-title">
    <a href="entries/2024-08-15_linux-speedup.html">
        Linux Performance Tips
    </a>
</p> <em>2024-08-25</em><!-- POST CONTENT TEMPLATE -->

<article class="post-content">
        <a href="entries/2024-08-14_video-enhancement.html">#</a>
    <h2>Plan</h2>
<p><em>you can make a silk purse out of a sow&#39;s ear if you have a model that has spent it&#39;s whole life comparing them</em></p>
<ol>
<li>extract frames from original vid</li>
<li>Upscale/improve individual frames</li>
<li>Interpolate new frames into better video</li>
</ol>
<p>pip install -r requirements.txt</p>
<h3>First Pass</h3>
<h4>Upscale</h4>
<p><a href="https://huggingface.co/ai-forever/Real-ESRGAN">https://huggingface.co/ai-forever/Real-ESRGAN</a></p>
<p><a href="https://arxiv.org/abs/2107.10833">https://arxiv.org/abs/2107.10833</a></p>
<h4>Interpolate</h4>
<p><a href="https://github.com/nihui/rife-ncnn-vulkan">https://github.com/nihui/rife-ncnn-vulkan</a></p>
<p><a href="https://arxiv.org/abs/2011.06294">https://arxiv.org/abs/2011.06294</a></p>
<p><a href="https://github.com/nihui/rife-ncnn-vulkan/releases">https://github.com/nihui/rife-ncnn-vulkan/releases</a></p>
<hr>
<p>I&#39;ve lost the link to the original vid... but do have a video-only download from YouTube using... I forget it&#39;s name, will be in the history on music room machine. It gives a bunch of alternate versions in various formats, presumably I chose the one that looked best...</p>
<p><code>ffmpeg</code> is probably the tool for pulling out the frames.</p>
<pre><code>   python src/extract-frames.py
</code></pre>
<p>Ok, a little path tweaking and that appears to have worked, maybe. Very quick. Lots of files, final one being <code>frame_19257.png</code>. Doesn&#39;t look like it&#39;s the final frame in the original video, but good enough for now.</p>
<p>Not sure about this either - it&#39;s 160x120 px. Not entirely implausible, the vid is very old. But still, good enough for now.</p>
<p>Ok, for upscaling, Real-ESRGAN looked promising. Try that on a single frame.</p>
<pre><code>   python src/upscale-single.py
</code></pre>
<p>Ok, it tried CUDA on my very old GPU card, suggested I get a legacy version build for that. But it&#39;s a rubbish card anyway, CPU good enough for now.</p>
<p>Yay! That actually worked! <em>insert screenshots</em>.</p>
<p>Output is 640x480. It&#39;s nicely smoothed some of the image, some is still very chunky, and the text in the image (&quot;O&#39;Reilly&quot;) is <em>less</em> legible, but I reckon it&#39;s worth proceeding, doing a small batch to see how it fares with interpolation.</p>
<p>Ok, at the point where I should save this elsewhere. Done a <code>backup.sh</code> to copy onto 2nd drive on this machine, plus a GitHub repo. <code>.gitignore</code> includes the data dir, I don&#39;t want to risk hitting the file size limits or whatever.</p>
<p>Soon I should add a <code>requirements.txt</code></p>
<p>Ouch. It&#39;s taking about 20s per frame. Sums... about 107 hours for 19257 frames.</p>
<p>Other models at <a href="https://drive.google.com/drive/folders/16PlVKhTNkSyWFx52RPb2hXPIQveNGbxS">https://drive.google.com/drive/folders/16PlVKhTNkSyWFx52RPb2hXPIQveNGbxS</a> including a x2. Lets do this.</p>
<p>The example code has :</p>
<pre><code>model.load_weights(&#39;weights/RealESRGAN_x4.pth&#39;, download=True)
``

Tweaked to x2, that Just Worked.

Down to ~5s per frame. That seems more feasible, about a day on this CPU. On Colab..?

The result, 320x240px *insert screenshots* is way less pixelated. I *think* the faces have about the same amount of detail, only smoother. Text is again mangled, not a worry.

https://github.com/MSFTserver/colab-convert

Last things for tonight (23:30, 27.6°C in the office, Spain 2, England 1)
</code></pre>
<p>pip freeze &gt; requirements.txt</p>
<pre><code>
gitty bits...

Food, couch, Hawaii 5-0 (on Rai 4 lingua originale).

---

*...continued 40 hours later...*

Ok, so this upscaling will take a lot of time on my CPU-only office machine, and I expect the interpolation will take at least as long, ie. days in total.

But before planting things on Colab or wherever, it would make sense to figure out the next bit locally too. Just do a few seconds to sanity-check.

I have noted down Linux commands to maximise performance on a machine like this (with the help of Claude), but I won&#39;t bother right now unless I obviously need to.

Hmm. I didn&#39;t note the frame rate...

Ok, the original vid is 40 mins = 2400s. I got 19257 frames. 19257/2400 ~= 8 fps? For a very old camera that does sound ballpark.

Taking 5s for each frame to upscale.

How long would 10s of the original take? 10x8x5 = 400s = ~7 mins. Yeah.

*(I am outrageously bad at basic arithmetic, need to spell things out to stand a chance of getting sums right)*

Er, 80 frames..?

Here we go then, in `upscale-many.py`,
</code></pre>
<p>for i in range(1, 80):</p>
<pre><code>
*(also rubbish memory, `history| grep python`)*
</code></pre>
<p>python src/upscale-many.py</p>
<pre><code>
</code></pre>
<p>Processed 79 frames (7.90%) in 708.31 seconds</p>
<pre><code>
*Heh, out by one error. You should see my C code.*

I&#39;d better test by gluing the new frames into a vid.

Ask Claude.

I&#39;d better start by lifting the following out of `extract-frames.py`, note her in case I need it later:
</code></pre>
<p>// use absolute paths</p>
<p>video_path = os.path.abspath(&#39;data/before/orig-vid-only.mp4&#39;)
output_folder = os.path.abspath(&#39;data/frames&#39;)</p>
<pre><code>if not os.path.exists(output_folder):
    os.makedirs(output_folder)

( ... )
</code></pre>
<pre><code>
#### Reglue vid prompt

&gt;&gt; I have used the code below to extract frames from a video file. Can you please generate corresponding code that will join together images 1-80 back into a video in a non-lossy format and save it in the &#39;data/output&#39; directory.
*[source of src/extract-frames.py]*

Yay! First pass it gave me the result at 25 fps. Claude told me the parameter to change it back to the original 8.

Runs very fast.

I&#39;m not entirely convinced of the other encoding parameters Claude gave me, but they will do for now.

Time for dogwalk #2. I might as well run the upscale script a bit longer while we are out.
</code></pre>
<p>for i in range(1, 401):</p>
<pre><code>
I&#39;ve not done the sums. Just feels right.

I remixed to vid, that worked.

The result is very Mr.Blobby, but no worse. Is enough time to get an idea if it&#39;s doing any good.

Hmm, I&#39;m confused. I ran `images-vid.py` on the original frames, that looks a lot longer in time.

Yeah, the original comes out at 50s, the upscaled 16s. Repeat.

Ok Claude. Thank you Claude, you remembered markdown format :

# Explanation of Video Length Discrepancy

When creating a video from a series of images, the output video length can vary based on several factors:

1. **Frame Rate**: If you&#39;re not explicitly setting a frame rate, ffmpeg might be inferring one based on the input. Smaller images might be interpreted as having a lower frame rate, resulting in a longer video.

2. **Codec Behavior**: Some codecs might handle different image sizes differently, potentially affecting the output duration.

3. **Container Format**: The container format (like .avi) can influence how the video is packaged and interpreted.

To address these issues and ensure consistent output regardless of image size, while maintaining a lossless quality and using the .avi format, we need to:

1. Explicitly set the input frame rate
2. Use a lossless codec compatible with .avi
3. Ensure the output frame rate matches the input frame rate

Here&#39;s an updated script that should produce consistent results:

...

Ok, after a bit of tweaking, and getting confused about which code file I was looking at (at 1:25 on an empty stomach), it is now behaving. Really can&#39;t tell if things are any better.

But you definitely can make a silk purse out of a sow&#39;s ear if you have a model trained on lots of silk purses.

Ok, so far so good.

I now eat.





















### Setup

_in home/danny/foaf-archive-support_
</code></pre>
<p>python3 -m venv video-magic</p>
<pre><code>
I will want a `.gitignore` soon, just so I can tell Cursor to ignore it when analysing the whole codebase.

I asked Cursor about the environment :
</code></pre>
<p>my_project/
├── src/
│ └── main.py
├── venv/
├── .env
└── ...</p>
<p>python3 -m venv venv
source venv/bin/activate</p>
<pre><code>  pip install -r requirements.txt
</code></pre>
<h1>.env</h1>
<p>HUB_BASE_URL=<a href="https://api.notefile.net">https://api.notefile.net</a>
HUB_AUTH_TOKEN=your_auth_token
HUB_PROJECT_UID=your_project_uid
HUB_PRODUCT_UID=your_product_uid</p>
<pre><code>  import os
</code></pre>
<p>from dotenv import load_dotenv</p>
<p>load_dotenv()</p>
<p>hub_base_url = os.getenv(&#39;HUB_BASE_URL&#39;)
hub_auth_token = os.getenv(&#39;HUB_AUTH_TOKEN&#39;)
hub_project_uid = os.getenv(&#39;HUB_PROJECT_UID&#39;)
hub_product_uid = os.getenv(&#39;HUB_PRODUCT_UID&#39;)</p>
<p>print(f&quot;Base URL: {hub_base_url}&quot;)
print(f&quot;Auth Token: {hub_auth_token}&quot;)
print(f&quot;Project UID: {hub_project_uid}&quot;)
print(f&quot;Product UID: {hub_product_uid}&quot;)</p>
<p>pip install python-dotenv</p>
<p>python src/main.py</p>
<pre><code>
AI also suggested, I don&#39;t know if I&#39;ll need this, we&#39;ll see :
</code></pre>
<p>pip install python-dotenv</p>
<pre><code>
Create a .env file in the root of your project:
</code></pre>
<h1>.env</h1>
<p>HUB_BASE_URL=<a href="https://api.notefile.net">https://api.notefile.net</a>
HUB_AUTH_TOKEN=your_auth_token
HUB_PROJECT_UID=your_project_uid
HUB_PRODUCT_UID=your_product_uid</p>
<pre><code>
use as:
</code></pre>
<p>import os
from dotenv import load_dotenv</p>
<p>load_dotenv()</p>
<p>hub_base_url = os.getenv(&#39;HUB_BASE_URL&#39;)
hub_auth_token = os.getenv(&#39;HUB_AUTH_TOKEN&#39;)
hub_project_uid = os.getenv(&#39;HUB_PROJECT_UID&#39;)
hub_product_uid = os.getenv(&#39;HUB_PRODUCT_UID&#39;)</p>
<p>print(f&quot;Base URL: {hub_base_url}&quot;)
print(f&quot;Auth Token: {hub_auth_token}&quot;)
print(f&quot;Project UID: {hub_project_uid}&quot;)
print(f&quot;Product UID: {hub_product_uid}&quot;)</p>
<pre><code>
**nota bene** - must be in .gitignore

### ffmpeg
</code></pre>
<p>pip install ffmpeg-python</p>
<pre><code>
#### Real-ESRGAN

[PyTorch implementation of a Real-ESRGAN model](https://github.com/ai-forever/Real-ESRGAN) on GitHub.
</code></pre>
<p>pip install git+<a href="https://github.com/sberbank-ai/Real-ESRGAN.git">https://github.com/sberbank-ai/Real-ESRGAN.git</a></p>
<pre><code>
took a very long time, I think it pulled loads of CUDA libs, even though I don&#39;t have a usable GPU in this machine.

---
</code></pre>
<p>sudo -i
QT_QPA_PLATFORM=xcb
flatpak run io.github.tntwise.REAL-Video-Enhancer</p>
<pre><code>
https://github.com/TNTwise/REAL-Video-Enhancer/issues/8

https://askubuntu.com/questions/1086529/how-to-give-a-flatpak-app-access-to-a-directory

https://docs.flatpak.org/en/latest/sandbox-permissions.html

https://docs.flatpak.org/en/latest/flatpak-command-reference.html

---

flatpak-spawn --host cp /run/host/root/Videos/output-video.avi_640x480.mp4 ~/output-video.avi_640x480.mp4

sudo -E flatpak enter 177213 sh
cp /root/Videos/output-video.avi_640x480.mp4 /home/danny/flatpak-exports/output-video.avi_640x480.mp4
exit
</code></pre>

</article>
<p class="post-title">
    <a href="entries/2024-08-14_video-enhancement.html">
         Plan
    </a>
</p> <em>2024-08-25</em><!-- POST CONTENT TEMPLATE -->

<article class="post-content">
        <a href="entries/2024-07-27_xordle.html">#</a>
    <p>Please write code for a single page browser app that will implement the following word game :</p>
<ul>
<li>It has a dictionary of all well-know words (including proper nouns, hyphenated words and pop culture references) beginning with the letter X</li>
<li>On load, internally a word is chosen at random</li>
<li>The player is presented with a row of single-character entry boxes, the first one filled in, with a green background, with the letter X</li>
<li>the number of entry boxes corresponds to the length of the target word</li>
<li>the player fill in their guess at the word</li>
<li>if the word is the the correct one, it shows a &quot;You Win!&quot; message. Otherwise the boxes are filled in with the correct answer, and a &quot;you lose!&quot; message is shown</li>
<li>a &quot;Play Again?&quot; button is shown, which will start another game</li>
</ul>

</article>
<p class="post-title">
    <a href="entries/2024-07-27_xordle.html">
        Xordle
    </a>
</p> <em>2024-08-25</em>
            </article>
        </div>
        <div class="main-grid-item about">
            <!--
            <h2>About</h2>
            
            -->
        </div>
    </div>
</body>

</html>